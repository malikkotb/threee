"use client";
import React, { useEffect, useRef } from "react";
import * as THREE from "three";
import { OrbitControls } from "three/examples/jsm/controls/OrbitControls.js";
import GUI from "lil-gui";
import gsap from "gsap";

/* Textures */

// UV unwrapping
// UV unwrapping is the process of mapping a 3D model's surface onto a 2D plane.
// It's used to create textures for the model.
// it's like unwrapping an origami or a candy wrap to make it flat
// each vertex will have a 2D coordinate on a flat plane (usually a square)
// const uvUnwrapSrc = "/uv-unwrapping.png";

// we can see those UV coordinates in geometry.attributes.uv

// those uv coordinates are generated by Three.js
// if u create your own geometry you'll have to specify the UV coordinates
// if you are making the geometry using a 3d software you'll also have to do the UV unwrapping

export default function GeometriesPage() {
  const canvasRef = useRef(null);
  const debugObject = {};

  useEffect(() => {
    if (!canvasRef.current) return;

    // Debug UI
    const gui = new GUI({ width: 300, title: "Debug UI" });
    gui.close();

    // Scene
    const scene = new THREE.Scene();

    // Textures

    const loadingManager = new THREE.LoadingManager();
    const textureLoader = new THREE.TextureLoader(loadingManager);

    const colorTexture = textureLoader.load(
      "/textures/checkerboard-8x8.png"
    );
    colorTexture.colorSpace = THREE.SRGBColorSpace;
    const alphaTexture = textureLoader.load(
      "/textures/door/alpha.jpg"
    );
    const heightTexture = textureLoader.load(
      "/textures/door/height.jpg"
    );
    const normalTexture = textureLoader.load(
      "/textures/door/normal.jpg"
    );

    // Transforming the texture
    // repeat the texture by using repeat property (Vector2 with x and y properties)
    // colorTexture.repeat.x = 2;
    // colorTexture.repeat.y = 3;
    // colorTexture.wrapS = THREE.RepeatWrapping;
    // colorTexture.wrapT = THREE.RepeatWrapping;

    // offset
    // colorTexture.offset.x = 0.5;
    // colorTexture.offset.y = 0.5;

    // rotation (this will be in 2d space, because the texture is 2d)
    // colorTexture.rotation = Math.PI / 4;

    // Filtering and mipmapping
    /*
      Mipmapping (or "mip mapping" with a space) is a technique that consists of creating 
      half a smaller version of a texture again and again until you get a 1x1 texture. 
      All those texture variations are sent to the GPU, 
      and the GPU will choose the most appropriate version of the texture.

      Three.js and the GPU already handle all of this,
      and you can just set what filter algorithm to use. 
      There are two types of filter algorithms: the minification filter and the magnification filter.
    */

    

    // Minification filter
    // if you are not happy with how blurry a result is, you can test other minification filters
    // colorTexture.minFilter = THREE.LinearFilter;

    // magnification filter
    colorTexture.magFilter = THREE.NearestFilter;

    // Object
    debugObject.color = "#35b673";
    const geometry = new THREE.BoxGeometry(1, 1, 1, 2, 2, 2);

    const material = new THREE.MeshBasicMaterial({
      map: colorTexture,
    });
    const mesh = new THREE.Mesh(geometry, material);
    scene.add(mesh);

    // magnification filter
    colorTexture.magFilter = THREE.NearestFilter;

    // range
    // the object is mesh.position and the property is y
    gui
      .add(mesh.position, "y")
      .min(-3)
      .max(3)
      .step(0.01)
      .name("elevation");

    // Sizes
    const sizes = {
      width: window.innerWidth,
      height: window.innerHeight,
    };

    // Camera
    const camera = new THREE.PerspectiveCamera(
      75,
      sizes.width / sizes.height,
      0.1,
      100
    );
    camera.position.z = 3;
    scene.add(camera);

    // Controls
    const controls = new OrbitControls(camera, canvasRef.current);
    controls.enableDamping = true;

    // Renderer
    const renderer = new THREE.WebGLRenderer({
      canvas: canvasRef.current,
    });
    renderer.setSize(sizes.width, sizes.height);
    renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));

    // Resize
    const onResize = () => {
      sizes.width = window.innerWidth;
      sizes.height = window.innerHeight;

      camera.aspect = sizes.width / sizes.height;
      camera.updateProjectionMatrix();

      renderer.setSize(sizes.width, sizes.height);
      renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
    };
    window.addEventListener("resize", onResize);

    // Animate
    let animationFrameId;

    const tick = () => {
      // const elapsedTime = clock.getElapsedTime();

      // update controls
      controls.update();

      // Render
      renderer.render(scene, camera);

      animationFrameId = window.requestAnimationFrame(tick);
    };

    // call tick again on the next frame
    tick();

    // Cleanup
    return () => {
      window.removeEventListener("resize", onResize);
      if (animationFrameId) cancelAnimationFrame(animationFrameId);
      controls.dispose();
      geometry.dispose();
      material.dispose();
      renderer.dispose();
    };
  }, []);

  return <canvas ref={canvasRef} className='webgl' />;
}
